{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c97ab368"
      },
      "source": [
        "# Task\n",
        "Langchain, Langgraph, Tavily Search를 사용하여 다음 기능을 포함하는 딥 리서치 도구를 개발합니다.\n",
        "1. 검색이 필요하지 않으면 검색을 수행하지 않습니다.\n",
        "2. 검색 결과는 최소 2개에서 최대 10개까지 활용합니다.\n",
        "3. 보고서 작성 목표를 생성하는 노드를 포함합니다.\n",
        "4. 목표 달성 여부를 확인하는 노드를 포함합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a86c099"
      },
      "source": [
        "# 실습 코드\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8l2AtjLNZXw"
      },
      "source": [
        "### 환경 셋팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTvruSZrNTZK",
        "outputId": "e1e01ef9-4219-4a44-bebf-23c59c87022c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.5/443.5 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain_openai langchain-community pypdf langgraph tavily-python langchain-tavily langfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4AYMkc6JNM8o"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import time\n",
        "from typing import List, Dict, Any\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfPHIUV8NW8p"
      },
      "source": [
        "### key 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_YoV3FLUNRT4"
      },
      "outputs": [],
      "source": [
        "# .env 파일에서 로드 (시크릿은 코드에 넣지 말고 .env에 작성)\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYYdHwVcNieX"
      },
      "source": [
        "### LLM 및 검색 도구 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ImGWtA5FNM1A"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4.1\",\n",
        "    temperature=0.2,\n",
        "    max_retries=2,\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")\n",
        "\n",
        "from langchain_tavily import TavilySearch\n",
        "tavily_tool = TavilySearch(\n",
        "    max_results=5,\n",
        "    topic=\"general\",\n",
        "    search_depth=\"advanced\",\n",
        "    include_raw_content=True,\n",
        "    tavily_api_key=TAVILY_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H5iXoZjNmwP"
      },
      "source": [
        "### 상태 정의 및 유틸 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nAYkF1ETNMCO"
      },
      "outputs": [],
      "source": [
        "class GraphState(TypedDict, total=False):\n",
        "    question: str\n",
        "    need_search: bool\n",
        "    queries: List[str]\n",
        "    search_results: List[Dict[str, str]]  # {title, url, content}\n",
        "    report_goal: str\n",
        "    report: str\n",
        "    goal_achieved: bool\n",
        "    iterations: int\n",
        "\n",
        "def _dedup_results(items: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for it in items:\n",
        "        key = (it.get(\"url\") or \"\").strip() or (it.get(\"title\") or \"\").strip() or (it.get(\"content\") or \"\")[:120]\n",
        "        if key and key not in seen:\n",
        "            seen.add(key)\n",
        "            out.append(it)\n",
        "    return out\n",
        "\n",
        "def _limit_max(items: List[Dict[str, str]], max_n: int = 10) -> List[Dict[str, str]]:\n",
        "    return items[:max_n] if len(items) > max_n else items\n",
        "\n",
        "def _format_results_for_prompt(results: List[Dict[str, str]]) -> str:\n",
        "    lines = []\n",
        "    for i, r in enumerate(results, 1):\n",
        "        lines.append(\n",
        "            f\"[{i}] {r.get('title','(제목 없음)')}\\nURL: {r.get('url','')}\\n{(r.get('content','') or '')[:1200]}\\n\"\n",
        "        )\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def _trueish(s: str) -> bool:\n",
        "    s = (s or \"\").strip().lower()\n",
        "    return s.startswith(\"t\") or s in {\"yes\", \"y\", \"1\", \"true\", \"참\", \"예\", \"네\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK5gVSFGNr5v"
      },
      "source": [
        "### 노드 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J97xoTEnOESo"
      },
      "outputs": [],
      "source": [
        "# 검색 필요 여부 판단\n",
        "def assess_search_need_node(state: GraphState) -> Dict[str, Any]:\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\",\n",
        "         \"당신은 사용자의 질문에 웹 검색이 필요한지 여부를 판정하는 엄격한 라우터입니다. \"\n",
        "         \"오직 'True' 또는 'False'만 답변하세요. \"\n",
        "         \"최신 사실, 가격, 법률, 최근 사건, 고유명사 검증, 외부 인용이 필요한 경우 True를 반환하세요. \"\n",
        "         \"시간에 무관한 일반 지식이나 의견이라면 False를 반환하세요.\"),\n",
        "        (\"human\", \"질문: {question}\\n웹 검색이 필요한가요? (True/False)\")\n",
        "    ])\n",
        "    chain = prompt | llm\n",
        "    resp = chain.invoke({\"question\": question}).content.strip()\n",
        "    need_search = _trueish(resp)\n",
        "    print(f\"[판정] 검색 필요 여부 = {need_search}  (LLM 응답: {resp})\")\n",
        "    return {\"need_search\": need_search, \"iterations\": state.get(\"iterations\", 0)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aAeZToPmOFcp"
      },
      "outputs": [],
      "source": [
        "# 검색 쿼리 생성\n",
        "def generate_queries_node(state: GraphState) -> Dict[str, Any]:\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\",\n",
        "         \"사용자의 질문에 답하기 위한 웹 검색 쿼리를 구체적으로 생성하세요. \"\n",
        "         \"중복 없이 1~3개 생성하고, 각 줄에 하나씩 작성하세요.\"),\n",
        "        (\"human\", \"현재 날짜 기준(Asia/Seoul).\\n질문: {question}\\n검색 쿼리:\")\n",
        "    ])\n",
        "    chain = prompt | llm\n",
        "    raw = chain.invoke({\"question\": question}).content\n",
        "    queries = [q.strip(\"- •\\t \").strip() for q in raw.split(\"\\n\") if q.strip()]\n",
        "    queries = [q for q in queries if len(q) > 1][:3]\n",
        "    if len(queries) < 2:\n",
        "        queries = list(dict.fromkeys(queries + [question]))[:2]\n",
        "    print(f\"[쿼리 생성] {queries}\")\n",
        "    return {\"queries\": queries}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oaMakEz-OJFv"
      },
      "outputs": [],
      "source": [
        "# 검색 실행\n",
        "def search_node(state: GraphState) -> Dict[str, Any]:\n",
        "    print(\"---검색 실행---\")\n",
        "    queries = state.get(\"queries\") or [state[\"question\"]]\n",
        "    collected: List[Dict[str, str]] = []\n",
        "\n",
        "    def _do_search(q: str, attempt: int = 0):\n",
        "        try:\n",
        "            res = tavily_tool.invoke({\"query\": q})\n",
        "            for r in res.get(\"results\", []):\n",
        "                collected.append({\n",
        "                    \"title\": r.get(\"title\", \"\") or \"\",\n",
        "                    \"url\": r.get(\"url\", \"\") or \"\",\n",
        "                    \"content\": r.get(\"content\", \"\") or r.get(\"raw_content\", \"\") or \"\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"[검색 오류] {e}\")\n",
        "            if attempt == 0:\n",
        "                time.sleep(1.2)\n",
        "                _do_search(q, attempt=1)\n",
        "\n",
        "    for q in queries:\n",
        "        if len(collected) >= 10:\n",
        "            break\n",
        "        _do_search(q)\n",
        "\n",
        "    collected = _dedup_results(collected)\n",
        "\n",
        "    if len(collected) < 2:\n",
        "        _do_search(state[\"question\"])\n",
        "        collected = _dedup_results(collected)\n",
        "\n",
        "    collected = _limit_max(collected, max_n=10)\n",
        "    print(f\"[검색 결과] {len(collected)}개 수집 완료\")\n",
        "    return {\"search_results\": collected}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B3kJK0eWONgX"
      },
      "outputs": [],
      "source": [
        "# 보고서 목표 생성\n",
        "def generate_report_goal_node(state: GraphState) -> Dict[str, Any]:\n",
        "    print(\"---보고서 목표 생성---\")\n",
        "    question = state[\"question\"]\n",
        "    search_results = state.get(\"search_results\", [])\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"간결하고 검증 가능한 보고서 목표를 정의하세요. \"\n",
        "                   \"범위, 핵심 질문, 전달물 형식, 성공 기준을 1~3문장으로 작성하세요.\"),\n",
        "        (\"human\", \"질문: {question}\\n\\n자료:\\n{sources}\\n\\n목표만 작성하세요.\")\n",
        "    ])\n",
        "    chain = prompt | llm\n",
        "    goal = chain.invoke({\n",
        "        \"question\": question,\n",
        "        \"sources\": _format_results_for_prompt(search_results) if search_results else \"(외부 자료 없음)\"\n",
        "    }).content.strip()\n",
        "\n",
        "    print(f\"[목표] {goal}\")\n",
        "    return {\"report_goal\": goal}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "41m5nrw8OOHJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 보고서 작성\n",
        "def synthesize_report_node(state: GraphState) -> Dict[str, Any]:\n",
        "    print(\"---보고서 작성---\")\n",
        "    question = state[\"question\"]\n",
        "    results = state.get(\"search_results\", [])\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\",\n",
        "         \"간결하고 증거 기반의 보고서를 작성하세요. \"\n",
        "         \"구성: 개요, 발견사항, 분석, 한계, 결론. \"\n",
        "         \"출처는 [n] 형식으로 인용하고, 불확실성은 명확히 언급하세요.\"),\n",
        "        (\"human\", \"질문: {question}\\n\\n자료:\\n{sources}\\n\\n보고서를 작성하세요.\")\n",
        "    ])\n",
        "    chain = prompt | llm\n",
        "    report = chain.invoke({\n",
        "        \"question\": question,\n",
        "        \"sources\": _format_results_for_prompt(results) if results else \"(외부 자료 없음)\"\n",
        "    }).content.strip()\n",
        "\n",
        "    return {\"report\": report}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UwcU4DEAORq_"
      },
      "outputs": [],
      "source": [
        "# 목표 달성 여부 판단\n",
        "def check_goal_achieved_node(state: GraphState) -> Dict[str, Any]:\n",
        "    print(\"---목표 달성 여부 판단---\")\n",
        "    report_goal = state.get(\"report_goal\", \"\")\n",
        "    report = state.get(\"report\", \"\")\n",
        "    sources = _format_results_for_prompt(state.get(\"search_results\", []))\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\",\n",
        "         \"보고서가 목표를 달성했는지 판단하세요. \"\n",
        "         \"엄격하게 'True' 또는 'False'만 반환하세요.\"),\n",
        "        (\"human\",\n",
        "         \"보고서 목표:\\n{goal}\\n\\n보고서:\\n{report}\\n\\n출처:\\n{sources}\\n\\n달성 여부:\")\n",
        "    ])\n",
        "    chain = prompt | llm\n",
        "    resp = chain.invoke({\"goal\": report_goal, \"report\": report, \"sources\": sources}).content.strip()\n",
        "    achieved = _trueish(resp)\n",
        "    print(f\"[달성 여부] {achieved} (원본 응답: {resp})\")\n",
        "    return {\"goal_achieved\": achieved}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uKlJ0Rf0M2HB"
      },
      "outputs": [],
      "source": [
        "# 쿼리 정련\n",
        "def refine_queries_node(state: GraphState) -> Dict[str, Any]:\n",
        "    print(\"---쿼리 정련---\")\n",
        "    report_goal = state.get(\"report_goal\", \"\")\n",
        "    report = state.get(\"report\", \"\")\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\",\n",
        "         \"목표와 현재 보고서를 바탕으로, 증거 부족을 해소할 수 있는 후속 검색 쿼리 최대 3개를 제안하세요.\"),\n",
        "        (\"human\", \"목표:\\n{goal}\\n\\n현재 보고서:\\n{report}\\n\\n쿼리:\")\n",
        "    ])\n",
        "    chain = prompt | llm\n",
        "    raw = chain.invoke({\"goal\": report_goal, \"report\": report}).content\n",
        "    new_queries = [q.strip(\"- •\\t \").strip() for q in raw.split(\"\\n\") if q.strip()]\n",
        "    new_queries = [q for q in new_queries if len(q) > 1][:3]\n",
        "\n",
        "    prev = state.get(\"queries\", [])\n",
        "    merged = list(dict.fromkeys(prev + new_queries))\n",
        "    print(f\"[정련된 쿼리] {new_queries}\")\n",
        "    return {\"queries\": merged, \"iterations\": state.get(\"iterations\", 0) + 1}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F17DA5dyOUWH"
      },
      "outputs": [],
      "source": [
        "def route_need_search(state: GraphState) -> str:\n",
        "    return \"search\" if state.get(\"need_search\") else \"skip\"\n",
        "\n",
        "def route_goal(state: GraphState) -> str:\n",
        "    return \"done\" if state.get(\"goal_achieved\") else \"not_done\"\n",
        "\n",
        "def route_continue_or_stop(state: GraphState) -> str:\n",
        "    if state.get(\"iterations\", 0) >= 3:\n",
        "        return \"stop\"\n",
        "    if len(state.get(\"search_results\", [])) >= 10:\n",
        "        return \"stop\"\n",
        "    return \"continue\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPBYp8xCN2iv"
      },
      "source": [
        "### Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Vh2ZDNXtN2KP"
      },
      "outputs": [],
      "source": [
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "workflow.add_node(\"assess_search_need\", assess_search_need_node)\n",
        "workflow.add_node(\"generate_queries\", generate_queries_node)\n",
        "workflow.add_node(\"search\", search_node)\n",
        "workflow.add_node(\"generate_report_goal\", generate_report_goal_node)\n",
        "workflow.add_node(\"synthesize_report\", synthesize_report_node)\n",
        "workflow.add_node(\"check_goal_achieved\", check_goal_achieved_node)\n",
        "workflow.add_node(\"refine_queries\", refine_queries_node)\n",
        "\n",
        "workflow.set_entry_point(\"assess_search_need\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"assess_search_need\",\n",
        "    route_need_search,\n",
        "    {\"search\": \"generate_queries\", \"skip\": \"generate_report_goal\"},\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"generate_queries\", \"search\")\n",
        "workflow.add_edge(\"search\", \"generate_report_goal\")\n",
        "workflow.add_edge(\"generate_report_goal\", \"synthesize_report\")\n",
        "workflow.add_edge(\"synthesize_report\", \"check_goal_achieved\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"check_goal_achieved\",\n",
        "    route_goal,\n",
        "    {\"done\": END, \"not_done\": \"refine_queries\"},\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"refine_queries\",\n",
        "    route_continue_or_stop,\n",
        "    {\"continue\": \"search\", \"stop\": \"synthesize_report\"},\n",
        ")\n",
        "\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEpbJPPCN8mI"
      },
      "source": [
        "### Test Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq9WmCqJN1Po",
        "outputId": "a0ae3864-ed69-41c0-f4b1-12abf2cffbfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[판정] 검색 필요 여부 = True  (LLM 응답: True)\n",
            "[쿼리 생성] ['2024 삼성라이온즈 시즌 경기력 평가', '2024 KBO 삼성라이온즈 팀 분석', '2024 삼성라이온즈 성적 및 선수별 활약']\n",
            "---검색 실행---\n",
            "[검색 결과] 6개 수집 완료\n",
            "---보고서 목표 생성---\n",
            "[목표] 보고서 목표:  \n",
            "2024시즌 삼성 라이온즈의 경기력을 정량적·정성적으로 평가하여, 정규시즌 및 포스트시즌 성과, 주요 전력 변화, 강·약점, 성공 요인을 분석한다.  \n",
            "범위는 2024년 정규시즌 및 포스트시즌 전체이며, 핵심 질문은 \"삼성 라이온즈가 예상을 깨고 준우승에 오른 주요 원동력과 한계는 무엇인가?\"이다.  \n",
            "전달물은 표와 그래프를 포함한 요약 보고서(PDF)이며, 성공 기준은 주요 성과와 개선점을 명확히 도출하고, 객관적 데이터와 비교 분석을 통해 구체적 인사이트를 제공하는 것이다.\n",
            "---보고서 작성---\n",
            "---목표 달성 여부 판단---\n",
            "[달성 여부] True (원본 응답: True)\n",
            "\n",
            "\n",
            "===== 보고서 =====\n",
            "\n",
            "### 2024 시즌 삼성 라이온즈 경기력 평가 보고서\n",
            "\n",
            "#### 1. 개요\n",
            "2024년 삼성 라이온즈는 전문가들의 예상을 뒤엎고 정규시즌 2위(78승 2무 64패, 승률 0.549)를 기록하며 3년 만에 포스트시즌에 진출, 9년 만에 한국시리즈에 올랐다. 최종적으로 준우승에 머물렀으나, 전년도 8위에서의 반등과 팀 컬러의 변화, 세대교체 등 여러 측면에서 의미 있는 시즌을 보냈다[1][4][6].\n",
            "\n",
            "#### 2. 발견사항\n",
            "- **정규시즌 성적**: 2위(78승 2무 64패, 승률 0.549)[1][3][4]\n",
            "- **홈/원정 승률**: 홈 0.562(41승 32패), 원정 0.536(37승 2무 32패)로 큰 차이 없이 안정적[1]\n",
            "- **타격**: 팀 타율 0.269(9위), 홈런 185개(1위), 장타율 0.428(3위), OPS 0.774(5위)[1][3][6]\n",
            "- **투수**: 팀 평균자책점 4.68(3위), WHIP 1.45(1위), 세이브 41개(2위), 홀드 116개(1위), 블론세이브 25개(2위)[1][2]\n",
            "- **포스트시즌**: 플레이오프에서 LG에 3승 1패로 승리, 한국시리즈에서 KIA에 1승 4패로 준우승[4]\n",
            "\n",
            "#### 3. 분석\n",
            "- **타격**: 팀 타율과 득점권 타율은 하위권(각각 9위)이었으나, 홈런 1위(185개)와 장타율 3위로 ‘빅볼’ 전략이 성공적으로 정착했다. 이는 이진영 타격코치 영입 이후 장타 중심의 타격 전략 전환과 대구구장의 특성이 맞물린 결과로 평가된다. 구자욱(33개), 김영웅(28개), 박병호(23개), 이성규(22개) 등 다수의 장타자가 두드러졌다[1][5][6].\n",
            "- **투수력**: 선발진은 평균자책점 4.68(3위), WAR 1위(21.01)로 리그 상위권을 기록했다. 불펜진은 홀드 1위(116개), 세이브 2위(41개), 수성률 81.8%로 강점을 보였으나, 블론세이브(25개)도 많아 불안요소가 존재했다. WHIP 1.45로 출루 허용은 적었으나, 탈삼진은 9위로 압도적이지 않았다[1][2][6].\n",
            "- **팀 컬러 및 전략 변화**: 2023년 스몰볼에서 2024년 빅볼로의 전환이 성공적이었다. 세대교체가 이루어진 야수진과 안정된 5선발 체제, 불펜의 강세가 상승세의 원동력이었다[5][6].\n",
            "- **경기력 흐름**: 시즌 초반 홈에서 부진했으나 중반 이후 승수를 쌓으며 회복, 원정에서는 초반 강세 후 후반에 다소 부진했다. 특정 구장(사직, 고척, 창원)에서는 강세, 문학, 광주에서는 약세를 보였다[1].\n",
            "- **포스트시즌**: 주요 선수 부상 등으로 전력 누수가 있었고, 한국시리즈에서 KIA에 밀려 준우승에 그쳤다[4].\n",
            "\n",
            "#### 4. 한계\n",
            "- **타율 및 득점력**: 팀 타율과 득점권 타율이 하위권에 머물러, 장타 외의 득점 루트가 부족했다는 점이 한계로 지적된다.\n",
            "- **불펜의 기복**: 블론세이브가 많았고, 시즌 후반 불펜의 피로 누적 및 부진이 나타났다[2].\n",
            "- **포스트시즌 전력 누수**: 부상 등으로 인한 전력 공백이 한국시리즈에서 뚜렷하게 드러났다. 이에 대한 정량적 분석은 제한적이었으나, 결과적으로 경기력 저하로 이어졌다[4].\n",
            "- **데이터 불확실성**: 일부 세부 WAR, 세이브 상황 등 세이버메트릭스 수치는 출처별로 차이가 있어 해석에 주의가 필요하다[2].\n",
            "\n",
            "#### 5. 결론\n",
            "2024년 삼성 라이온즈는 전년도 8위에서 정규시즌 2위, 한국시리즈 준우승으로 반등하며 ‘빅볼’ 전략의 성공, 세대교체, 투수진의 안정 등 긍정적 변화를 이끌었다. 타율 등 전통적 지표는 약점이었으나, 장타력과 불펜의 강세로 이를 상쇄했다. 시즌 후반 불펜 부진, 포스트시즌 부상 등 한계도 분명했으나, 예상을 뛰어넘는 성과와 팀 컬러의 변화는 다음 시즌에 대한 기대감을 높였다. 다만, 타선의 다양화와 불펜의 체력 관리, 부상 방지 등 보완이 필요하다[1][2][4][6].\n",
            "\n",
            "---\n",
            "**출처**  \n",
            "[1] 나무위키 삼성 라이온즈/2024년  \n",
            "[2] 나무위키 삼성 라이온즈/2024년/총평  \n",
            "[3] KBO 공식 Facebook  \n",
            "[4] 위키백과 2024년 삼성 라이온즈 시즌  \n",
            "[5] 네이버 블로그  \n",
            "[6] 한국연예스포츠신문\n",
            "\n",
            "===== 목표 =====\n",
            "\n",
            "보고서 목표:  \n",
            "2024시즌 삼성 라이온즈의 경기력을 정량적·정성적으로 평가하여, 정규시즌 및 포스트시즌 성과, 주요 전력 변화, 강·약점, 성공 요인을 분석한다.  \n",
            "범위는 2024년 정규시즌 및 포스트시즌 전체이며, 핵심 질문은 \"삼성 라이온즈가 예상을 깨고 준우승에 오른 주요 원동력과 한계는 무엇인가?\"이다.  \n",
            "전달물은 표와 그래프를 포함한 요약 보고서(PDF)이며, 성공 기준은 주요 성과와 개선점을 명확히 도출하고, 객관적 데이터와 비교 분석을 통해 구체적 인사이트를 제공하는 것이다.\n",
            "\n",
            "===== 달성 여부 =====\n",
            "\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "question = \"이번 시즌 삼성라이온즈 경기력 평가 보고서 작성해줘\"\n",
        "result_state = app.invoke({\"question\": question})\n",
        "\n",
        "print(\"\\n\\n===== 보고서 =====\\n\")\n",
        "print(result_state.get(\"report\", \"\"))\n",
        "print(\"\\n===== 목표 =====\\n\")\n",
        "print(result_state.get(\"report_goal\", \"\"))\n",
        "print(\"\\n===== 달성 여부 =====\\n\")\n",
        "print(result_state.get(\"goal_achieved\", \"\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
