# ai_discussion/app.py - Streamlit ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ (LangGraph AI í† ë¡ )
import streamlit as st
from openai import APIConnectionError

import core.config  # noqa: F401 - load_dotenv ë° LLM/ì„ë² ë”© ì´ˆê¸°í™”
from core.config import check_env_set, get_connection_troubleshooting
from core.state import DebateStatus, DebateState, SpeakerRole
from graph import create_debate_graph
from rag import create_vector_store

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI í† ë¡ ", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– AI í† ë¡  - LangGraph & RAG ë²„ì „")
st.markdown(
    """
    ### í”„ë¡œì íŠ¸ ì†Œê°œ
    ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ LangGraphë¥¼ í™œìš©í•˜ì—¬ AI ì—ì´ì „íŠ¸ ê°„ì˜ í† ë¡  ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
    ì°¬ì„± ì¸¡, ë°˜ëŒ€ ì¸¡, ê·¸ë¦¬ê³  ì‹¬íŒ ì—­í• ì˜ AIê°€ ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ì²´ê³„ì ìœ¼ë¡œ í† ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤.
    RAG(Retrieval-Augmented Generation)ë¥¼ í†µí•´ ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ ë” ê°•ë ¥í•œ ë…¼ë¦¬ë¥¼ í¼ì¹©ë‹ˆë‹¤.
    """
)

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
if "debate_active" not in st.session_state:
    st.session_state.debate_active = False
    st.session_state.debate_messages = []
    st.session_state.vector_store = None
    st.session_state.retrieved_docs = {"pro": [], "con": []}

# ì‚¬ì´ë“œë°”: ì„¤ì •
with st.sidebar:
    st.header("í† ë¡  ì„¤ì •")
    debate_topic = st.text_input(
        "í† ë¡  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", "ì¸ê³µì§€ëŠ¥ì´ ì¸ê°„ì˜ ì¼ìë¦¬ë¥¼ ëŒ€ì²´í•´ì•¼ í•œë‹¤"
    )
    max_rounds = st.slider("í† ë¡  ë¼ìš´ë“œ ìˆ˜", min_value=1, max_value=5, value=1)
    enable_rag = st.checkbox(
        "RAG í™œì„±í™”", value=True, help="ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ í† ë¡ ì— í™œìš©í•©ë‹ˆë‹¤."
    )
    show_sources = st.checkbox(
        "ì¶œì²˜ í‘œì‹œ", value=True, help="ê²€ìƒ‰ëœ ì •ë³´ì˜ ì¶œì²˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."
    )

# í† ë¡  ì‹œì‘
if not st.session_state.debate_active and st.button("í† ë¡  ì‹œì‘"):
    ok, missing = check_env_set()
    if not ok:
        st.error(f"í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëˆ„ë½: **{missing}** â€” `.env` íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    st.session_state.vector_store = None
    st.session_state.retrieved_docs = {"pro": [], "con": []}

    if enable_rag:
        with st.spinner("ì™¸ë¶€ ì§€ì‹ì„ ìˆ˜ì§‘í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            vector_store = create_vector_store(debate_topic)
            st.session_state.vector_store = vector_store
            if vector_store:
                st.success("ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰ ì¤€ë¹„ ì™„ë£Œ!")
            else:
                st.warning(
                    "ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰ì„ ìœ„í•œ ì¤€ë¹„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ í† ë¡ ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤."
                )

    debate_graph = create_debate_graph()
    initial_state: DebateState = {
        "topic": debate_topic,
        "messages": [],
        "current_round": 1,
        "max_rounds": max_rounds,
        "current_speaker": SpeakerRole.PRO,
        "debate_status": DebateStatus.ACTIVE,
        "vector_store": st.session_state.vector_store,
        "retrieved_docs": {"pro": [], "con": []},
        "current_query": "",
        "current_context": "",
    }

    try:
        with st.spinner("í† ë¡ ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤... ì™„ë£Œê¹Œì§€ ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            result = debate_graph.invoke(initial_state)
            st.session_state.debate_messages = result["messages"]
            st.session_state.debate_active = True
            st.session_state.retrieved_docs = result.get(
                "retrieved_docs", {"pro": [], "con": []}
            )
        st.rerun()
    except APIConnectionError:
        st.error("**Azure OpenAIì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.** (Connection error)")
        st.markdown(get_connection_troubleshooting())
        st.stop()

# í† ë¡  ë‚´ìš© í‘œì‹œ
if st.session_state.debate_active:
    st.header(f"í† ë¡  ì£¼ì œ: {debate_topic}")
    st.header("í† ë¡  ì§„í–‰ ìƒí™©")

    messages = st.session_state.debate_messages
    total_rounds = len([m for m in messages if m["role"] == "ì°¬ì„± ì¸¡"])

    for round_num in range(1, total_rounds + 1):
        st.subheader(f"ë¼ìš´ë“œ {round_num}")
        pro_index = (round_num - 1) * 2
        if pro_index < len(messages) and messages[pro_index]["role"] == "ì°¬ì„± ì¸¡":
            with st.container(border=True):
                st.markdown("**ğŸ”µ ì°¬ì„± ì¸¡:**")
                st.write(messages[pro_index]["content"])

        con_index = (round_num - 1) * 2 + 1
        if con_index < len(messages) and messages[con_index]["role"] == "ë°˜ëŒ€ ì¸¡":
            with st.container(border=True):
                st.markdown("**ğŸ”´ ë°˜ëŒ€ ì¸¡:**")
                st.write(messages[con_index]["content"])
        st.divider()

    if messages and messages[-1]["role"] == "ì‹¬íŒ":
        with st.container(border=True):
            st.subheader("ğŸ§‘â€âš–ï¸ ìµœì¢… í‰ê°€")
            st.write(messages[-1]["content"])

    if (
        show_sources
        and st.session_state.retrieved_docs
        and (
            st.session_state.retrieved_docs.get("pro")
            or st.session_state.retrieved_docs.get("con")
        )
    ):
        with st.expander("ì‚¬ìš©ëœ ì°¸ê³  ìë£Œ ë³´ê¸°"):
            st.subheader("ì°¬ì„± ì¸¡ ì°¸ê³  ìë£Œ")
            for i, doc in enumerate(
                st.session_state.retrieved_docs.get("pro", [])[:3]
            ):
                st.markdown(f"**ì¶œì²˜ {i+1}**")
                st.text(doc[:300] + "..." if len(doc) > 300 else doc)
                st.divider()
            st.subheader("ë°˜ëŒ€ ì¸¡ ì°¸ê³  ìë£Œ")
            for i, doc in enumerate(
                st.session_state.retrieved_docs.get("con", [])[:3]
            ):
                st.markdown(f"**ì¶œì²˜ {i+1}**")
                st.text(doc[:300] + "..." if len(doc) > 300 else doc)
                st.divider()

    if st.button("ìƒˆ í† ë¡  ì‹œì‘"):
        st.session_state.debate_active = False
        st.session_state.debate_messages = []
        st.session_state.vector_store = None
        st.session_state.retrieved_docs = {"pro": [], "con": []}
        st.rerun()
